{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5068, 3)\n",
      "(4424, 3)\n",
      "(0, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Pedro./anaconda3/lib/python3.7/site-packages/pandas/core/ops.py:1649: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movie_id  cluster_avg_rating user_729846_rating\n",
      "0         1            4.000000                  4\n",
      "1         8            5.000000                  ?\n",
      "2        17            4.000000                  ?\n",
      "3        28            4.500000                  5\n",
      "4        30            4.666667                  ?\n",
      "?    1747\n",
      "4     256\n",
      "5     220\n",
      "3     117\n",
      "2      32\n",
      "1      19\n",
      "Name: user_729846_rating, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "# Reads the json with all the clusters for each user\n",
    "path = os.getcwd()[:os.getcwd().find(\"Code\")] + \"/Data/user-clusters/clusters.json\"\n",
    "with open(path, \"r\") as s:\n",
    "    clusters = json.loads(s.read())\n",
    "\n",
    "# Gets the cluster of users for user 729846\n",
    "similar_users_to_729846 = [int(user) for user in clusters[\"729846\"].split()] + [729846]\n",
    "\n",
    "# Reads the downsampled dataframe and gets the data for the users in user 729846 cluster, including itself\n",
    "df = pd.read_csv(os.getcwd()[:os.getcwd().find(\"Code\")] + \"/Data/netflix-prize/downsampled-csv/few_samples.csv\", index_col=0)\n",
    "df_729846 = df[df[\"user_id\"].isin(similar_users_to_729846)]\n",
    "print(df_729846.shape)\n",
    "print(df[df[\"user_id\"].isin([int(user) for user in clusters[\"729846\"].split()])].shape)\n",
    "\n",
    "# Example of how to get the DataFrame to be augmented with IMDb data \n",
    "# (add features for each movie) and then to be used to train our models\n",
    "movie_ids = []\n",
    "movies_avg_rating = []\n",
    "user_729846_ratings = []\n",
    "for movie_id in df_729846[\"movie_id\"].unique():\n",
    "    movie_ids.append(movie_id)\n",
    "    movies_avg_rating.append(df_729846[df_729846[\"movie_id\"] == movie_id][\"rating\"].mean())\n",
    "    try:\n",
    "        user_729846_ratings.append(df_729846[(df_729846[\"movie_id\"] == movie_id) & (df_729846[\"user_id\"] == 729846)][\"rating\"].iloc[0])\n",
    "    except IndexError:\n",
    "        user_729846_ratings.append(\"?\")\n",
    "    \n",
    "df_729846 = pd.DataFrame({\"movie_id\": movie_ids, \"cluster_avg_rating\": movies_avg_rating, \"user_729846_rating\": user_729846_ratings})\n",
    "print(df_729846.head())\n",
    "print(df_729846[\"user_729846_rating\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0    256\n",
      "5.0    220\n",
      "3.0    117\n",
      "2.0     32\n",
      "1.0     19\n",
      "Name: user_729846_rating, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df_729846.replace(\"?\", np.NaN, inplace=True)\n",
    "df_729846.dropna(inplace=True)\n",
    "print(df_729846[\"user_729846_rating\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8502632013835584"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = df_729846.drop(\"user_729846_rating\", axis=1)\n",
    "y = df_729846[\"user_729846_rating\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8757437943876125"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing this for all the users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from time import time\n",
    "\n",
    "#Â Reads the downsampled dataframe\n",
    "df = pd.read_csv(os.getcwd()[:os.getcwd().find(\"Code\")] + \"/Data/netflix-prize/downsampled-csv/few_samples.csv\", index_col=0)\n",
    "# Reads the json with all the clusters for each user\n",
    "path = os.getcwd()[:os.getcwd().find(\"Code\")] + \"/Data/user-clusters/clusters.json\"\n",
    "with open(path, \"r\") as s:\n",
    "    clusters = json.loads(s.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"729846\" in df[\"user_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have trained and scored models on 100 users, and it has taken 9 seconds\n",
      "We have trained and scored models on 200 users, and it has taken 15 seconds\n",
      "We have trained and scored models on 300 users, and it has taken 22 seconds\n",
      "error: 1569028\n",
      "We have trained and scored models on 400 users, and it has taken 27 seconds\n",
      "We have trained and scored models on 500 users, and it has taken 32 seconds\n",
      "We have trained and scored models on 600 users, and it has taken 37 seconds\n",
      "We have trained and scored models on 700 users, and it has taken 42 seconds\n",
      "We have trained and scored models on 800 users, and it has taken 47 seconds\n",
      "We have trained and scored models on 900 users, and it has taken 51 seconds\n",
      "We have trained and scored models on 1000 users, and it has taken 57 seconds\n",
      "We have trained and scored models on 1100 users, and it has taken 61 seconds\n",
      "We have trained and scored models on 1200 users, and it has taken 66 seconds\n",
      "We have trained and scored models on 1300 users, and it has taken 71 seconds\n",
      "We have trained and scored models on 1400 users, and it has taken 76 seconds\n",
      "We have trained and scored models on 1500 users, and it has taken 82 seconds\n",
      "We have trained and scored models on 1600 users, and it has taken 87 seconds\n",
      "We have trained and scored models on 1700 users, and it has taken 92 seconds\n",
      "We have trained and scored models on 1800 users, and it has taken 97 seconds\n",
      "We have trained and scored models on 1900 users, and it has taken 102 seconds\n"
     ]
    }
   ],
   "source": [
    "# Trains and scores a basic linear regression model for each user\n",
    "lr = LinearRegression()\n",
    "r_squared = {}\n",
    "user_count = 0\n",
    "problem_users = []\n",
    "timer = 0\n",
    "for user in clusters.keys():\n",
    "    \n",
    "    start = time()\n",
    "\n",
    "    # Gets the cluster of users for user\n",
    "    similar_users_to_user = [int(user) for user in clusters[user].split()]\n",
    "    # Gets the data for the users in user cluster\n",
    "    df_user_cluster = df[df[\"user_id\"].isin(similar_users_to_user)]\n",
    "    df_user = df[df[\"user_id\"].isin([user])]\n",
    "\n",
    "    # mprint(\"a\", time() - start)\n",
    "\n",
    "    # start = time()\n",
    "    \n",
    "    groups = df_user_cluster.groupby(\"movie_id\")\n",
    "    movies_avg_rating = groups[\"rating\"].mean().values\n",
    "    movies_avg_rating = groups[\"rating\"].mean()#.values\n",
    "    df_user = pd.merge(movies_avg_rating, df_user, on=\"movie_id\")\n",
    "    del df_user[\"user_id\"]\n",
    "    df_user.columns = [\"movie_id\", \"cluster_avg_rating\", \"user_rating\"]\n",
    "    \n",
    "    df_user.replace(\"?\", np.NaN, inplace=True)\n",
    "    df_user.dropna(inplace=True)\n",
    "    try:\n",
    "        if min(df_user[\"user_rating\"].value_counts()) == 1:  # Condition to avoid error on train_test_split\n",
    "            # ValueError: The least populated class in y has only 1 member, which is too few. \n",
    "            # The minimum number of groups for any class cannot be less than 2.\n",
    "            problem_users.append(user)\n",
    "        else:\n",
    "            X = df_user.drop(\"user_rating\", axis=1)\n",
    "            y = df_user[\"user_rating\"]\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "            lr.fit(X_train, y_train)\n",
    "            r_squared[user] = lr.score(X_test, y_test)\n",
    "    except:\n",
    "        print(\"error:\", user)\n",
    "\n",
    "    timer += time() - start\n",
    "    user_count += 1\n",
    "    if user_count % 100 == 0:\n",
    "        print(\"We have trained and scored models on\", user_count, \"users,\", \n",
    "             \"and it has taken\", round(timer), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4777365567179733"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(list(r_squared.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "sorted_r_squared = sorted(r_squared.items(), key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1915847', 1.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_r_squared[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1516635', 0.8236819966430549)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_r_squared[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1392040', 0.7477141110932599)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_r_squared[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('262823', -1.4826263035137188)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_r_squared[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2096898', -0.18986049201666177)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_r_squared[-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"user_id\"] == 262823].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"user_id\"] == 2096898].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('59510', -0.020923608297436447)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_r_squared[-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(433, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"user_id\"] == 59510].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
