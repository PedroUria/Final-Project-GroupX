{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5068, 3)\n",
      "(4424, 3)\n",
      "(0, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Pedro./anaconda3/lib/python3.7/site-packages/pandas/core/ops.py:1649: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movie_id  cluster_avg_rating user_729846_rating\n",
      "0         1            4.000000                  4\n",
      "1         8            5.000000                  ?\n",
      "2        17            4.000000                  ?\n",
      "3        28            4.500000                  5\n",
      "4        30            4.666667                  ?\n",
      "?    1747\n",
      "4     256\n",
      "5     220\n",
      "3     117\n",
      "2      32\n",
      "1      19\n",
      "Name: user_729846_rating, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "# Reads the json with all the clusters for each user\n",
    "path = os.getcwd()[:os.getcwd().find(\"Code\")] + \"/Data/user-clusters/clusters.json\"\n",
    "with open(path, \"r\") as s:\n",
    "    clusters = json.loads(s.read())\n",
    "\n",
    "# Gets the cluster of users for user 729846\n",
    "similar_users_to_729846 = [int(user) for user in clusters[\"729846\"].split()] + [729846]\n",
    "\n",
    "# Reads the downsampled dataframe and gets the data for the users in user 729846 cluster, including itself\n",
    "df = pd.read_csv(os.getcwd()[:os.getcwd().find(\"Code\")] + \"/Data/netflix-prize/downsampled-csv/few_samples.csv\", index_col=0)\n",
    "df_729846 = df[df[\"user_id\"].isin(similar_users_to_729846)]\n",
    "print(df_729846.shape)\n",
    "print(df[df[\"user_id\"].isin([int(user) for user in clusters[\"729846\"].split()])].shape)\n",
    "\n",
    "# Example of how to get the DataFrame to be augmented with IMDb data \n",
    "# (add features for each movie) and then to be used to train our models\n",
    "movie_ids = []\n",
    "movies_avg_rating = []\n",
    "user_729846_ratings = []\n",
    "for movie_id in df_729846[\"movie_id\"].unique():\n",
    "    movie_ids.append(movie_id)\n",
    "    movies_avg_rating.append(df_729846[df_729846[\"movie_id\"] == movie_id][\"rating\"].mean())\n",
    "    try:\n",
    "        user_729846_ratings.append(df_729846[(df_729846[\"movie_id\"] == movie_id) & (df_729846[\"user_id\"] == 729846)][\"rating\"].iloc[0])\n",
    "    except IndexError:\n",
    "        user_729846_ratings.append(\"?\")\n",
    "    \n",
    "df_729846 = pd.DataFrame({\"movie_id\": movie_ids, \"cluster_avg_rating\": movies_avg_rating, \"user_729846_rating\": user_729846_ratings})\n",
    "print(df_729846.head())\n",
    "print(df_729846[\"user_729846_rating\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0    256\n",
      "5.0    220\n",
      "3.0    117\n",
      "2.0     32\n",
      "1.0     19\n",
      "Name: user_729846_rating, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df_729846.replace(\"?\", np.NaN, inplace=True)\n",
    "df_729846.dropna(inplace=True)\n",
    "print(df_729846[\"user_729846_rating\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8502632013835584"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = df_729846.drop(\"user_729846_rating\", axis=1)\n",
    "y = df_729846[\"user_729846_rating\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8757437943876125"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing this for all the users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from time import time\n",
    "\n",
    "# Reads the downsampled dataframe\n",
    "df = pd.read_csv(os.getcwd()[:os.getcwd().find(\"Code\")] + \"/Data/netflix-prize/downsampled-csv/few_samples.csv\", index_col=0)\n",
    "# Reads the json with all the clusters for each user\n",
    "path = os.getcwd()[:os.getcwd().find(\"Code\")] + \"/Data/user-clusters/clusters.json\"\n",
    "with open(path, \"r\") as s:\n",
    "    clusters = json.loads(s.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Pedro./anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have trained and scored models on 100 users, and it has taken 12 seconds\n",
      "We have trained and scored models on 200 users, and it has taken 21 seconds\n",
      "We have trained and scored models on 300 users, and it has taken 30 seconds\n",
      "We have trained and scored models on 400 users, and it has taken 39 seconds\n",
      "We have trained and scored models on 500 users, and it has taken 48 seconds\n",
      "We have trained and scored models on 600 users, and it has taken 57 seconds\n",
      "We have trained and scored models on 700 users, and it has taken 67 seconds\n",
      "We have trained and scored models on 800 users, and it has taken 76 seconds\n",
      "We have trained and scored models on 900 users, and it has taken 85 seconds\n",
      "We have trained and scored models on 1000 users, and it has taken 95 seconds\n",
      "We have trained and scored models on 1100 users, and it has taken 104 seconds\n",
      "We have trained and scored models on 1200 users, and it has taken 112 seconds\n",
      "We have trained and scored models on 1300 users, and it has taken 122 seconds\n",
      "We have trained and scored models on 1400 users, and it has taken 130 seconds\n",
      "We have trained and scored models on 1500 users, and it has taken 138 seconds\n",
      "We have trained and scored models on 1600 users, and it has taken 147 seconds\n",
      "We have trained and scored models on 1700 users, and it has taken 158 seconds\n",
      "We have trained and scored models on 1800 users, and it has taken 166 seconds\n",
      "We have trained and scored models on 1900 users, and it has taken 174 seconds\n"
     ]
    }
   ],
   "source": [
    "# Trains and scores a basic linear regression model for each user\n",
    "lr = LinearRegression()\n",
    "r_squared = {}\n",
    "rf = RandomForestRegressor()\n",
    "rf_scores = {}\n",
    "dumb_scores = {}\n",
    "rg = Ridge()\n",
    "rg_squared = {}\n",
    "ls = Lasso()\n",
    "rls_squared = {}\n",
    "ada = AdaBoostRegressor()\n",
    "ada_scores = {}\n",
    "\n",
    "user_count = 0\n",
    "problem_users = []\n",
    "timer = 0\n",
    "for user in clusters.keys():\n",
    "    \n",
    "    start = time()\n",
    "\n",
    "    # Gets the cluster of users for user\n",
    "    similar_users_to_user = [int(user) for user in clusters[user].split()] # + [int(user)] -> CHEATING!!!\n",
    "    # Gets the data for the users in user cluster\n",
    "    df_user_cluster = df[df[\"user_id\"].isin(similar_users_to_user)]\n",
    "    df_user = df[df[\"user_id\"].isin([user])]\n",
    "    \n",
    "    groups = df_user_cluster.groupby(\"movie_id\")\n",
    "    movies_avg_rating = groups[\"rating\"].mean()\n",
    "    df_user = pd.merge(movies_avg_rating, df_user, on=\"movie_id\")\n",
    "    del df_user[\"user_id\"]\n",
    "    df_user.columns = [\"movie_id\", \"cluster_avg_rating\", \"user_rating\"]\n",
    "    \n",
    "    df_user.replace(\"?\", np.NaN, inplace=True)\n",
    "    df_user.dropna(inplace=True)\n",
    "    try:\n",
    "        if min(df_user[\"user_rating\"].value_counts()) == 1:  # Condition to avoid error on train_test_split\n",
    "            # ValueError: The least populated class in y has only 1 member, which is too few. \n",
    "            # The minimum number of groups for any class cannot be less than 2.\n",
    "            problem_users.append(user)\n",
    "        else:\n",
    "            X = df_user.drop([\"user_rating\", \"movie_id\"], axis=1)\n",
    "            y = df_user[\"user_rating\"]\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "            lr.fit(X_train, y_train)\n",
    "            r_squared[user] = lr.score(X_test, y_test)\n",
    "            rf.fit(X_train, y_train)\n",
    "            rf_scores[user] = rf.score(X_test, y_test)\n",
    "            dumb_scores[user] = r2_score(y_test.values, X_test.values)\n",
    "            rg.fit(X_train, y_train)\n",
    "            rg_squared[user] = rg.score(X_test, y_test)\n",
    "            ls.fit(X_train, y_train)\n",
    "            rls_squared[user] = ls.score(X_test, y_test)\n",
    "            ada.fit(X_train, y_train)\n",
    "            ada_scores[user] = ada.score(X_test, y_test)\n",
    "            \n",
    "    except:\n",
    "        print(\"error:\", user)\n",
    "\n",
    "    timer += time() - start\n",
    "    user_count += 1\n",
    "    if user_count % 100 == 0:\n",
    "        print(\"We have trained and scored models on\", user_count, \"users,\", \n",
    "             \"and it has taken\", round(timer), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7079287311044233"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(list(r_squared.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.626843155418488"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(list(rf_scores.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6662820033937438"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(list(dumb_scores.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7085752294215808"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(list(rg_squared.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07135146218528511"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(list(rls_squared.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6689402493060858"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(list(ada_scores.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "sorted_r_squared = sorted(r_squared.items(), key=operator.itemgetter(1), reverse=True)\n",
    "sorted_rf_scores = sorted(rf_scores.items(), key=operator.itemgetter(1), reverse=True)\n",
    "sorted_dumb_scores = sorted(dumb_scores.items(), key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1915847', 1.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_r_squared[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1915847', 1.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_rf_scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1915847', 1.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_r_squared[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1516635', 0.8236819966430549)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_r_squared[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1915847', 1.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_rf_scores[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1392040', 0.7477141110932599)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_r_squared[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('262823', -1.4826263035137188)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_r_squared[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2096898', -0.18986049201666177)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_r_squared[-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"user_id\"] == 262823].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"user_id\"] == 2096898].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('59510', -0.020923608297436447)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_r_squared[-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(433, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"user_id\"] == 59510].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
